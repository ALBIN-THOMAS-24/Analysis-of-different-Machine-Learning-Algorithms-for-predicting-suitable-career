{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#GROUP MEMBERS\n",
    "#ALBIN THOMAS ,07\n",
    "#ALEX P.L ,09\n",
    "#ALEN K VARGHESE ,08\n",
    "#BOBBY JOSEPH MATHEWS ,21"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project: Optimal Career Prediction System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ANALYSIS OF DIFFERENT SUPERVISED MACHINE LEARNING  ALGORITHMS\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# SCIENCE DATASET: 4.5 LAKH\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQ</th>\n",
       "      <th>PHYSICS</th>\n",
       "      <th>CHEMISTRY</th>\n",
       "      <th>MATHS</th>\n",
       "      <th>BIOLOGY</th>\n",
       "      <th>COMPUTER</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>OPENNESS</th>\n",
       "      <th>CONSCIENTIOUSNESS</th>\n",
       "      <th>EXTRAVERSION</th>\n",
       "      <th>...</th>\n",
       "      <th>SATISFACTION</th>\n",
       "      <th>SOCIO-ECONOMIC-FACTORS</th>\n",
       "      <th>M-SCORE</th>\n",
       "      <th>TEAM-WORK</th>\n",
       "      <th>COMPETIVE-EXAM-WINNER</th>\n",
       "      <th>LEADERSHIP-SKILL</th>\n",
       "      <th>WORK-LIFE-BALANCE</th>\n",
       "      <th>CERTIFICATIONS</th>\n",
       "      <th>SELF-LEARNING-CAPABILITY</th>\n",
       "      <th>CAREER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.008651</td>\n",
       "      <td>-0.646053</td>\n",
       "      <td>1.483130</td>\n",
       "      <td>-0.491651</td>\n",
       "      <td>-0.420337</td>\n",
       "      <td>0.029624</td>\n",
       "      <td>-0.099065</td>\n",
       "      <td>1.703846</td>\n",
       "      <td>-1.874724</td>\n",
       "      <td>-0.747657</td>\n",
       "      <td>...</td>\n",
       "      <td>0.223245</td>\n",
       "      <td>-2.721022</td>\n",
       "      <td>1.265528</td>\n",
       "      <td>0.119911</td>\n",
       "      <td>0.566785</td>\n",
       "      <td>-1.951926</td>\n",
       "      <td>1.116503</td>\n",
       "      <td>-1.483536</td>\n",
       "      <td>0.617054</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.516545</td>\n",
       "      <td>3.135103</td>\n",
       "      <td>-1.042419</td>\n",
       "      <td>-1.371282</td>\n",
       "      <td>0.088652</td>\n",
       "      <td>-0.926914</td>\n",
       "      <td>1.186076</td>\n",
       "      <td>-0.148570</td>\n",
       "      <td>1.267581</td>\n",
       "      <td>-0.104341</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.733354</td>\n",
       "      <td>-0.983299</td>\n",
       "      <td>-0.672728</td>\n",
       "      <td>-0.564505</td>\n",
       "      <td>-0.895462</td>\n",
       "      <td>-0.296227</td>\n",
       "      <td>0.455496</td>\n",
       "      <td>-1.440636</td>\n",
       "      <td>-0.353796</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.330520</td>\n",
       "      <td>-0.449276</td>\n",
       "      <td>-0.746021</td>\n",
       "      <td>-0.224562</td>\n",
       "      <td>-0.511844</td>\n",
       "      <td>-0.068503</td>\n",
       "      <td>-0.488076</td>\n",
       "      <td>-0.456048</td>\n",
       "      <td>-0.329565</td>\n",
       "      <td>0.672229</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746915</td>\n",
       "      <td>-1.010269</td>\n",
       "      <td>0.278442</td>\n",
       "      <td>0.257752</td>\n",
       "      <td>-0.151023</td>\n",
       "      <td>0.304002</td>\n",
       "      <td>-0.218066</td>\n",
       "      <td>1.044610</td>\n",
       "      <td>1.421632</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.443553</td>\n",
       "      <td>-0.209296</td>\n",
       "      <td>0.475726</td>\n",
       "      <td>-0.255531</td>\n",
       "      <td>1.069152</td>\n",
       "      <td>0.152201</td>\n",
       "      <td>-1.291762</td>\n",
       "      <td>-0.817565</td>\n",
       "      <td>-0.159006</td>\n",
       "      <td>-1.424354</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.311611</td>\n",
       "      <td>-0.454171</td>\n",
       "      <td>-0.084505</td>\n",
       "      <td>-0.025262</td>\n",
       "      <td>-1.126085</td>\n",
       "      <td>-0.708699</td>\n",
       "      <td>-1.100454</td>\n",
       "      <td>0.500687</td>\n",
       "      <td>-0.726287</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.893850</td>\n",
       "      <td>0.374306</td>\n",
       "      <td>0.951791</td>\n",
       "      <td>-0.698985</td>\n",
       "      <td>-0.415257</td>\n",
       "      <td>-1.542616</td>\n",
       "      <td>-0.750294</td>\n",
       "      <td>1.453135</td>\n",
       "      <td>-1.727244</td>\n",
       "      <td>0.728515</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.227262</td>\n",
       "      <td>0.940326</td>\n",
       "      <td>-0.991811</td>\n",
       "      <td>1.142285</td>\n",
       "      <td>0.247072</td>\n",
       "      <td>0.467854</td>\n",
       "      <td>-0.131504</td>\n",
       "      <td>-0.165085</td>\n",
       "      <td>-1.098174</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-2.798029</td>\n",
       "      <td>-0.337010</td>\n",
       "      <td>1.689635</td>\n",
       "      <td>1.549443</td>\n",
       "      <td>-1.097144</td>\n",
       "      <td>0.743820</td>\n",
       "      <td>1.420239</td>\n",
       "      <td>0.179937</td>\n",
       "      <td>-0.467669</td>\n",
       "      <td>0.201903</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.142162</td>\n",
       "      <td>0.456954</td>\n",
       "      <td>-0.695542</td>\n",
       "      <td>0.326168</td>\n",
       "      <td>-1.191192</td>\n",
       "      <td>-0.989191</td>\n",
       "      <td>0.143072</td>\n",
       "      <td>1.060792</td>\n",
       "      <td>0.965897</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.689498</td>\n",
       "      <td>1.414032</td>\n",
       "      <td>-0.689225</td>\n",
       "      <td>-0.377121</td>\n",
       "      <td>-0.014630</td>\n",
       "      <td>1.350241</td>\n",
       "      <td>-0.935422</td>\n",
       "      <td>-1.031317</td>\n",
       "      <td>0.531610</td>\n",
       "      <td>-1.258476</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.110366</td>\n",
       "      <td>0.173484</td>\n",
       "      <td>-0.180160</td>\n",
       "      <td>0.114790</td>\n",
       "      <td>0.944251</td>\n",
       "      <td>-0.250260</td>\n",
       "      <td>-0.395578</td>\n",
       "      <td>-1.557932</td>\n",
       "      <td>-1.943085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-1.772473</td>\n",
       "      <td>0.228136</td>\n",
       "      <td>-0.161365</td>\n",
       "      <td>0.003763</td>\n",
       "      <td>-0.084336</td>\n",
       "      <td>0.061549</td>\n",
       "      <td>-0.512891</td>\n",
       "      <td>-0.611300</td>\n",
       "      <td>-1.361522</td>\n",
       "      <td>-0.400869</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.114975</td>\n",
       "      <td>1.174844</td>\n",
       "      <td>1.744942</td>\n",
       "      <td>1.237503</td>\n",
       "      <td>0.699977</td>\n",
       "      <td>1.508119</td>\n",
       "      <td>0.644319</td>\n",
       "      <td>-1.448363</td>\n",
       "      <td>-1.502030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.087134</td>\n",
       "      <td>0.165049</td>\n",
       "      <td>1.351920</td>\n",
       "      <td>0.126517</td>\n",
       "      <td>0.284113</td>\n",
       "      <td>0.917127</td>\n",
       "      <td>-1.589489</td>\n",
       "      <td>0.568392</td>\n",
       "      <td>0.772986</td>\n",
       "      <td>1.848414</td>\n",
       "      <td>...</td>\n",
       "      <td>0.950024</td>\n",
       "      <td>0.084734</td>\n",
       "      <td>-0.423183</td>\n",
       "      <td>-0.384590</td>\n",
       "      <td>-0.074684</td>\n",
       "      <td>0.696934</td>\n",
       "      <td>0.133869</td>\n",
       "      <td>0.728442</td>\n",
       "      <td>-0.155451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.577735</td>\n",
       "      <td>1.214914</td>\n",
       "      <td>0.540939</td>\n",
       "      <td>-0.703580</td>\n",
       "      <td>0.295974</td>\n",
       "      <td>1.035918</td>\n",
       "      <td>-1.112798</td>\n",
       "      <td>1.109826</td>\n",
       "      <td>1.646882</td>\n",
       "      <td>0.705301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.699247</td>\n",
       "      <td>1.113481</td>\n",
       "      <td>-1.030284</td>\n",
       "      <td>-0.984026</td>\n",
       "      <td>-0.914930</td>\n",
       "      <td>1.690874</td>\n",
       "      <td>-1.765382</td>\n",
       "      <td>-1.050837</td>\n",
       "      <td>-0.431092</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IQ   PHYSICS  CHEMISTRY     MATHS   BIOLOGY  COMPUTER  LANGUAGE  \\\n",
       "0 -1.008651 -0.646053   1.483130 -0.491651 -0.420337  0.029624 -0.099065   \n",
       "1 -0.516545  3.135103  -1.042419 -1.371282  0.088652 -0.926914  1.186076   \n",
       "2  1.330520 -0.449276  -0.746021 -0.224562 -0.511844 -0.068503 -0.488076   \n",
       "3 -1.443553 -0.209296   0.475726 -0.255531  1.069152  0.152201 -1.291762   \n",
       "4  0.893850  0.374306   0.951791 -0.698985 -0.415257 -1.542616 -0.750294   \n",
       "5 -2.798029 -0.337010   1.689635  1.549443 -1.097144  0.743820  1.420239   \n",
       "6  1.689498  1.414032  -0.689225 -0.377121 -0.014630  1.350241 -0.935422   \n",
       "7 -1.772473  0.228136  -0.161365  0.003763 -0.084336  0.061549 -0.512891   \n",
       "8 -1.087134  0.165049   1.351920  0.126517  0.284113  0.917127 -1.589489   \n",
       "9  1.577735  1.214914   0.540939 -0.703580  0.295974  1.035918 -1.112798   \n",
       "\n",
       "   OPENNESS  CONSCIENTIOUSNESS  EXTRAVERSION  ...  SATISFACTION  \\\n",
       "0  1.703846          -1.874724     -0.747657  ...      0.223245   \n",
       "1 -0.148570           1.267581     -0.104341  ...     -0.733354   \n",
       "2 -0.456048          -0.329565      0.672229  ...      0.746915   \n",
       "3 -0.817565          -0.159006     -1.424354  ...     -0.311611   \n",
       "4  1.453135          -1.727244      0.728515  ...     -1.227262   \n",
       "5  0.179937          -0.467669      0.201903  ...     -0.142162   \n",
       "6 -1.031317           0.531610     -1.258476  ...     -0.110366   \n",
       "7 -0.611300          -1.361522     -0.400869  ...     -1.114975   \n",
       "8  0.568392           0.772986      1.848414  ...      0.950024   \n",
       "9  1.109826           1.646882      0.705301  ...      0.699247   \n",
       "\n",
       "   SOCIO-ECONOMIC-FACTORS   M-SCORE  TEAM-WORK  COMPETIVE-EXAM-WINNER  \\\n",
       "0               -2.721022  1.265528   0.119911               0.566785   \n",
       "1               -0.983299 -0.672728  -0.564505              -0.895462   \n",
       "2               -1.010269  0.278442   0.257752              -0.151023   \n",
       "3               -0.454171 -0.084505  -0.025262              -1.126085   \n",
       "4                0.940326 -0.991811   1.142285               0.247072   \n",
       "5                0.456954 -0.695542   0.326168              -1.191192   \n",
       "6                0.173484 -0.180160   0.114790               0.944251   \n",
       "7                1.174844  1.744942   1.237503               0.699977   \n",
       "8                0.084734 -0.423183  -0.384590              -0.074684   \n",
       "9                1.113481 -1.030284  -0.984026              -0.914930   \n",
       "\n",
       "   LEADERSHIP-SKILL  WORK-LIFE-BALANCE  CERTIFICATIONS  \\\n",
       "0         -1.951926           1.116503       -1.483536   \n",
       "1         -0.296227           0.455496       -1.440636   \n",
       "2          0.304002          -0.218066        1.044610   \n",
       "3         -0.708699          -1.100454        0.500687   \n",
       "4          0.467854          -0.131504       -0.165085   \n",
       "5         -0.989191           0.143072        1.060792   \n",
       "6         -0.250260          -0.395578       -1.557932   \n",
       "7          1.508119           0.644319       -1.448363   \n",
       "8          0.696934           0.133869        0.728442   \n",
       "9          1.690874          -1.765382       -1.050837   \n",
       "\n",
       "   SELF-LEARNING-CAPABILITY  CAREER  \n",
       "0                  0.617054       1  \n",
       "1                 -0.353796       0  \n",
       "2                  1.421632       2  \n",
       "3                 -0.726287       1  \n",
       "4                 -1.098174       2  \n",
       "5                  0.965897       2  \n",
       "6                 -1.943085       0  \n",
       "7                 -1.502030       0  \n",
       "8                 -0.155451       1  \n",
       "9                 -0.431092       1  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#DISPLAY TOP 5 ROWS\n",
    "data = pd.read_csv(\"C:\\\\machine\\\\science-dataset.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.01022323e+00 -6.45237302e-01  1.11300196e+00 ...  1.11706852e+00\n",
      "  -1.48495673e+00  6.17447285e-01]\n",
      " [-5.17847197e-01  3.13543283e+00 -7.81765445e-01 ...  4.55098220e-01\n",
      "  -1.44202551e+00 -3.53916847e-01]\n",
      " [ 1.33023274e+00 -4.48486098e-01 -5.59395959e-01 ... -2.19445277e-01\n",
      "   1.04505909e+00  1.42245191e+00]\n",
      " ...\n",
      " [ 2.99809168e-02  1.63595665e-01  6.00358124e-01 ...  6.96918721e-01\n",
      "  -1.15012005e+00  5.91665972e-01]\n",
      " [ 8.01600072e-02  4.00059078e-01  1.33510530e+00 ... -6.37413053e-01\n",
      "   1.97773150e-03  5.83187598e-01]\n",
      " [-1.76164381e+00  7.60466658e-02 -2.21542851e-01 ... -1.21197124e+00\n",
      "  -1.27333845e+00 -2.70203358e-01]]\n",
      "(450000, 22)\n",
      "(450000,)\n"
     ]
    }
   ],
   "source": [
    "X=data.drop(['CAREER'], axis = 1).values\n",
    "#data.drop(['name'])\n",
    "from sklearn import preprocessing \n",
    "Standardisation = preprocessing.StandardScaler() \n",
    "AFTER_SCALE= Standardisation.fit_transform(X) \n",
    "X=AFTER_SCALE\n",
    "print(X)\n",
    "y = data['CAREER']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NAIVE-BAYES-ACCURACY => 86.3725 %\n",
      "Time= 0.1529829502105713\n",
      "[[11226   427  1645]\n",
      " [   93 13000   345]\n",
      " [ 2320   621 10323]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     13298\n",
      "           1       0.93      0.97      0.95     13438\n",
      "           2       0.84      0.78      0.81     13264\n",
      "\n",
      "    accuracy                           0.86     40000\n",
      "   macro avg       0.86      0.86      0.86     40000\n",
      "weighted avg       0.86      0.86      0.86     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NAIVE  BAYES\n",
    "import time\n",
    "start=time.time()\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive=GaussianNB()\n",
    "naive.fit(X_train,y_train)\n",
    "y_pred = naive.predict(X_test)\n",
    "print(\"'NAIVE-BAYES-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"Time=\",end-start)\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC-REGRESSION-ACCURACY => 84.75222222222222 %\n",
      "time= 4.109047889709473\n",
      "[[24605  2468  3058]\n",
      " [ 2746 25677  1508]\n",
      " [  954  2989 25995]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.82      0.84     30131\n",
      "           1       0.82      0.86      0.84     29931\n",
      "           2       0.85      0.87      0.86     29938\n",
      "\n",
      "    accuracy                           0.85     90000\n",
      "   macro avg       0.85      0.85      0.85     90000\n",
      "weighted avg       0.85      0.85      0.85     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "import time\n",
    "start=time.time()\n",
    "from sklearn import linear_model\n",
    "log=linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "log.fit(X_train,y_train)\n",
    "y_pred=(log.predict(X_test))\n",
    "print(\"LOGISTIC-REGRESSION-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\",end-start)\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP-ACCURACY => 92.19888888888889 %\n",
      "time=336.13990092277527\n",
      "[[27214   919  1998]\n",
      " [  835 27624  1472]\n",
      " [  685  1112 28141]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.90      0.92     30131\n",
      "           1       0.93      0.92      0.93     29931\n",
      "           2       0.89      0.94      0.91     29938\n",
      "\n",
      "    accuracy                           0.92     90000\n",
      "   macro avg       0.92      0.92      0.92     90000\n",
      "weighted avg       0.92      0.92      0.92     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#two hidden layers\n",
    "\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp= MLPClassifier(hidden_layer_sizes=(8,8), activation='relu', solver='adam',max_iter=200)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred=(mlp.predict(X_test))\n",
    "print(\"MLP-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\"+str(end-start))\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost-ACCURACY => 83.08555555555556 %\n",
      "time=136.58350372314453\n",
      "[[24277  2815  3039]\n",
      " [ 1768 25883  2280]\n",
      " [ 2498  2823 24617]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.81      0.83     30131\n",
      "           1       0.82      0.86      0.84     29931\n",
      "           2       0.82      0.82      0.82     29938\n",
      "\n",
      "    accuracy                           0.83     90000\n",
      "   macro avg       0.83      0.83      0.83     90000\n",
      "weighted avg       0.83      0.83      0.83     90000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Adaboost-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\"+str(end-start))\n",
    "\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************DECISION TREE***********************\n",
      "\n",
      "Predicted Value :\n",
      "[0 1 1 ... 0 0 2]\n",
      "\n",
      "Confusion Matrix : model evaluation\n",
      "[[26721  1386  2024]\n",
      " [ 1333 26598  2000]\n",
      " [ 1954  2153 25831]]\n",
      "\n",
      " Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     30131\n",
      "           1       0.88      0.89      0.89     29931\n",
      "           2       0.87      0.86      0.86     29938\n",
      "\n",
      "    accuracy                           0.88     90000\n",
      "   macro avg       0.88      0.88      0.88     90000\n",
      "weighted avg       0.88      0.88      0.88     90000\n",
      "\n",
      "\n",
      "Decision Tree Accuracy : \n",
      "87.94444444444444\n",
      "28.42\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#DECISION TREE\n",
    "print(\"******************DECISION TREE***********************\\n\")\n",
    "import time\n",
    "Start = time.time ()\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "Decision_tree= DecisionTreeClassifier(criterion = 'gini') \n",
    "Decision_tree.fit(X_train, y_train)\n",
    "Y_pred = Decision_tree.predict(X_test) \n",
    "print(\"Predicted Value :\")\n",
    "print(Y_pred)\n",
    "    \n",
    "print(\"\\nConfusion Matrix : model evaluation\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, Y_pred))\n",
    "    \n",
    "print(\"\\n Classification report :\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, Y_pred))\n",
    "    \n",
    "print(\"\\nDecision Tree Accuracy : \")\n",
    "from sklearn import metrics\n",
    "print((metrics.accuracy_score(y_test, Y_pred))*100)\n",
    "a2=(metrics.accuracy_score(y_test, Y_pred))*100\n",
    "end= time.time()\n",
    "b2=str(round(end-Start,2))\n",
    "print(b2)\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COMMERCE DATASET: 2 LAKH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQ</th>\n",
       "      <th>ACCOUNTANCY</th>\n",
       "      <th>BUSINESS STUDIES</th>\n",
       "      <th>ECONOMICS</th>\n",
       "      <th>ENGLISH</th>\n",
       "      <th>INFORMATION PRACTICES/MATHEMATICS</th>\n",
       "      <th>LEGAL STUDIES</th>\n",
       "      <th>OPENNESS</th>\n",
       "      <th>CONSCIENTIOUSNESS</th>\n",
       "      <th>EXTRAVERSION</th>\n",
       "      <th>...</th>\n",
       "      <th>SATISFACTION</th>\n",
       "      <th>SOCIO-ECONOMIC-FACTORS</th>\n",
       "      <th>M-SCORE</th>\n",
       "      <th>TEAM-WORK</th>\n",
       "      <th>COMPETIVE-EXAM-WINNER</th>\n",
       "      <th>LEADERSHIP-SKILL</th>\n",
       "      <th>WORK-LIFE-BALANCE</th>\n",
       "      <th>CERTIFICATIONS</th>\n",
       "      <th>SELF-LEARNING-CAPABILITY</th>\n",
       "      <th>CAREER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.245119</td>\n",
       "      <td>-0.851747</td>\n",
       "      <td>0.588909</td>\n",
       "      <td>1.529945</td>\n",
       "      <td>-1.611591</td>\n",
       "      <td>0.788213</td>\n",
       "      <td>-1.552692</td>\n",
       "      <td>1.256968</td>\n",
       "      <td>1.603721</td>\n",
       "      <td>-0.122566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083766</td>\n",
       "      <td>-0.350558</td>\n",
       "      <td>-0.707781</td>\n",
       "      <td>-2.139185</td>\n",
       "      <td>0.109520</td>\n",
       "      <td>-2.028669</td>\n",
       "      <td>-0.739035</td>\n",
       "      <td>0.838250</td>\n",
       "      <td>-1.972468</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.168922</td>\n",
       "      <td>0.031583</td>\n",
       "      <td>0.432711</td>\n",
       "      <td>-0.268296</td>\n",
       "      <td>0.970550</td>\n",
       "      <td>-0.459002</td>\n",
       "      <td>-0.653192</td>\n",
       "      <td>0.801030</td>\n",
       "      <td>1.101843</td>\n",
       "      <td>0.549276</td>\n",
       "      <td>...</td>\n",
       "      <td>1.976195</td>\n",
       "      <td>-0.849972</td>\n",
       "      <td>0.374115</td>\n",
       "      <td>-0.103719</td>\n",
       "      <td>-0.376152</td>\n",
       "      <td>0.172232</td>\n",
       "      <td>-1.013076</td>\n",
       "      <td>0.877472</td>\n",
       "      <td>-0.786797</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.041283</td>\n",
       "      <td>0.280792</td>\n",
       "      <td>-0.831895</td>\n",
       "      <td>1.397449</td>\n",
       "      <td>0.550499</td>\n",
       "      <td>0.377007</td>\n",
       "      <td>-0.800994</td>\n",
       "      <td>-0.671609</td>\n",
       "      <td>-0.396741</td>\n",
       "      <td>-1.193091</td>\n",
       "      <td>...</td>\n",
       "      <td>1.049190</td>\n",
       "      <td>0.382831</td>\n",
       "      <td>-0.057216</td>\n",
       "      <td>0.954195</td>\n",
       "      <td>-1.387928</td>\n",
       "      <td>0.048100</td>\n",
       "      <td>0.567865</td>\n",
       "      <td>0.839897</td>\n",
       "      <td>0.157779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.360363</td>\n",
       "      <td>-0.999669</td>\n",
       "      <td>1.142266</td>\n",
       "      <td>0.133847</td>\n",
       "      <td>2.033926</td>\n",
       "      <td>-1.289407</td>\n",
       "      <td>0.317987</td>\n",
       "      <td>-1.182210</td>\n",
       "      <td>-0.572107</td>\n",
       "      <td>-0.562029</td>\n",
       "      <td>...</td>\n",
       "      <td>0.096847</td>\n",
       "      <td>0.518845</td>\n",
       "      <td>1.408462</td>\n",
       "      <td>-1.446753</td>\n",
       "      <td>1.118879</td>\n",
       "      <td>-1.834134</td>\n",
       "      <td>-0.943777</td>\n",
       "      <td>-1.053905</td>\n",
       "      <td>0.970705</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.789811</td>\n",
       "      <td>-0.543417</td>\n",
       "      <td>0.328899</td>\n",
       "      <td>0.428675</td>\n",
       "      <td>-0.024837</td>\n",
       "      <td>0.310884</td>\n",
       "      <td>-0.601240</td>\n",
       "      <td>0.779158</td>\n",
       "      <td>-1.230092</td>\n",
       "      <td>-1.713011</td>\n",
       "      <td>...</td>\n",
       "      <td>0.565525</td>\n",
       "      <td>-0.280653</td>\n",
       "      <td>-0.856836</td>\n",
       "      <td>1.392418</td>\n",
       "      <td>-2.515866</td>\n",
       "      <td>-0.713385</td>\n",
       "      <td>-1.397114</td>\n",
       "      <td>-0.798758</td>\n",
       "      <td>-1.590746</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.437267</td>\n",
       "      <td>0.417079</td>\n",
       "      <td>0.085780</td>\n",
       "      <td>0.074520</td>\n",
       "      <td>0.277643</td>\n",
       "      <td>-1.103500</td>\n",
       "      <td>0.506591</td>\n",
       "      <td>1.018899</td>\n",
       "      <td>1.297995</td>\n",
       "      <td>-0.072008</td>\n",
       "      <td>...</td>\n",
       "      <td>1.720544</td>\n",
       "      <td>-0.679405</td>\n",
       "      <td>-0.116577</td>\n",
       "      <td>-1.581613</td>\n",
       "      <td>1.032171</td>\n",
       "      <td>-1.204232</td>\n",
       "      <td>-1.584098</td>\n",
       "      <td>0.786545</td>\n",
       "      <td>-0.092714</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.832572</td>\n",
       "      <td>1.629317</td>\n",
       "      <td>-0.582750</td>\n",
       "      <td>-1.784577</td>\n",
       "      <td>0.187788</td>\n",
       "      <td>-0.241932</td>\n",
       "      <td>1.597794</td>\n",
       "      <td>1.016708</td>\n",
       "      <td>-0.079366</td>\n",
       "      <td>0.185673</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.718099</td>\n",
       "      <td>-1.335331</td>\n",
       "      <td>-0.225129</td>\n",
       "      <td>0.756647</td>\n",
       "      <td>1.467213</td>\n",
       "      <td>0.020342</td>\n",
       "      <td>0.417134</td>\n",
       "      <td>-0.061786</td>\n",
       "      <td>-0.754360</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.372833</td>\n",
       "      <td>0.555250</td>\n",
       "      <td>-1.355800</td>\n",
       "      <td>0.605305</td>\n",
       "      <td>-1.212884</td>\n",
       "      <td>-0.664042</td>\n",
       "      <td>0.238459</td>\n",
       "      <td>-0.662637</td>\n",
       "      <td>0.648457</td>\n",
       "      <td>0.850449</td>\n",
       "      <td>...</td>\n",
       "      <td>1.830901</td>\n",
       "      <td>0.428492</td>\n",
       "      <td>-1.067491</td>\n",
       "      <td>-1.773033</td>\n",
       "      <td>-0.364809</td>\n",
       "      <td>0.971728</td>\n",
       "      <td>-1.676542</td>\n",
       "      <td>2.402972</td>\n",
       "      <td>-0.944793</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.460641</td>\n",
       "      <td>0.040167</td>\n",
       "      <td>-0.301129</td>\n",
       "      <td>0.366917</td>\n",
       "      <td>-0.690337</td>\n",
       "      <td>-0.403584</td>\n",
       "      <td>2.284197</td>\n",
       "      <td>1.919773</td>\n",
       "      <td>-0.777661</td>\n",
       "      <td>-0.229758</td>\n",
       "      <td>...</td>\n",
       "      <td>0.398724</td>\n",
       "      <td>1.917156</td>\n",
       "      <td>0.916942</td>\n",
       "      <td>1.549282</td>\n",
       "      <td>-0.184433</td>\n",
       "      <td>1.237519</td>\n",
       "      <td>1.210530</td>\n",
       "      <td>-0.305860</td>\n",
       "      <td>0.500771</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.277782</td>\n",
       "      <td>0.294056</td>\n",
       "      <td>1.349770</td>\n",
       "      <td>-0.332285</td>\n",
       "      <td>0.040868</td>\n",
       "      <td>0.242230</td>\n",
       "      <td>-1.850002</td>\n",
       "      <td>-1.301307</td>\n",
       "      <td>-3.079846</td>\n",
       "      <td>-0.497228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.803789</td>\n",
       "      <td>-0.092071</td>\n",
       "      <td>0.110709</td>\n",
       "      <td>2.052555</td>\n",
       "      <td>0.871248</td>\n",
       "      <td>0.747563</td>\n",
       "      <td>1.316871</td>\n",
       "      <td>0.222439</td>\n",
       "      <td>-0.003946</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IQ  ACCOUNTANCY  BUSINESS STUDIES  ECONOMICS   ENGLISH  \\\n",
       "0  0.245119    -0.851747          0.588909   1.529945 -1.611591   \n",
       "1 -1.168922     0.031583          0.432711  -0.268296  0.970550   \n",
       "2 -0.041283     0.280792         -0.831895   1.397449  0.550499   \n",
       "3  0.360363    -0.999669          1.142266   0.133847  2.033926   \n",
       "4 -0.789811    -0.543417          0.328899   0.428675 -0.024837   \n",
       "5  2.437267     0.417079          0.085780   0.074520  0.277643   \n",
       "6 -0.832572     1.629317         -0.582750  -1.784577  0.187788   \n",
       "7 -0.372833     0.555250         -1.355800   0.605305 -1.212884   \n",
       "8 -1.460641     0.040167         -0.301129   0.366917 -0.690337   \n",
       "9  0.277782     0.294056          1.349770  -0.332285  0.040868   \n",
       "\n",
       "   INFORMATION PRACTICES/MATHEMATICS  LEGAL STUDIES  OPENNESS  \\\n",
       "0                           0.788213      -1.552692  1.256968   \n",
       "1                          -0.459002      -0.653192  0.801030   \n",
       "2                           0.377007      -0.800994 -0.671609   \n",
       "3                          -1.289407       0.317987 -1.182210   \n",
       "4                           0.310884      -0.601240  0.779158   \n",
       "5                          -1.103500       0.506591  1.018899   \n",
       "6                          -0.241932       1.597794  1.016708   \n",
       "7                          -0.664042       0.238459 -0.662637   \n",
       "8                          -0.403584       2.284197  1.919773   \n",
       "9                           0.242230      -1.850002 -1.301307   \n",
       "\n",
       "   CONSCIENTIOUSNESS  EXTRAVERSION  ...  SATISFACTION  SOCIO-ECONOMIC-FACTORS  \\\n",
       "0           1.603721     -0.122566  ...      0.083766               -0.350558   \n",
       "1           1.101843      0.549276  ...      1.976195               -0.849972   \n",
       "2          -0.396741     -1.193091  ...      1.049190                0.382831   \n",
       "3          -0.572107     -0.562029  ...      0.096847                0.518845   \n",
       "4          -1.230092     -1.713011  ...      0.565525               -0.280653   \n",
       "5           1.297995     -0.072008  ...      1.720544               -0.679405   \n",
       "6          -0.079366      0.185673  ...     -1.718099               -1.335331   \n",
       "7           0.648457      0.850449  ...      1.830901                0.428492   \n",
       "8          -0.777661     -0.229758  ...      0.398724                1.917156   \n",
       "9          -3.079846     -0.497228  ...      0.803789               -0.092071   \n",
       "\n",
       "    M-SCORE  TEAM-WORK  COMPETIVE-EXAM-WINNER  LEADERSHIP-SKILL  \\\n",
       "0 -0.707781  -2.139185               0.109520         -2.028669   \n",
       "1  0.374115  -0.103719              -0.376152          0.172232   \n",
       "2 -0.057216   0.954195              -1.387928          0.048100   \n",
       "3  1.408462  -1.446753               1.118879         -1.834134   \n",
       "4 -0.856836   1.392418              -2.515866         -0.713385   \n",
       "5 -0.116577  -1.581613               1.032171         -1.204232   \n",
       "6 -0.225129   0.756647               1.467213          0.020342   \n",
       "7 -1.067491  -1.773033              -0.364809          0.971728   \n",
       "8  0.916942   1.549282              -0.184433          1.237519   \n",
       "9  0.110709   2.052555               0.871248          0.747563   \n",
       "\n",
       "   WORK-LIFE-BALANCE  CERTIFICATIONS  SELF-LEARNING-CAPABILITY  CAREER  \n",
       "0          -0.739035        0.838250                 -1.972468       0  \n",
       "1          -1.013076        0.877472                 -0.786797       0  \n",
       "2           0.567865        0.839897                  0.157779       1  \n",
       "3          -0.943777       -1.053905                  0.970705       0  \n",
       "4          -1.397114       -0.798758                 -1.590746       1  \n",
       "5          -1.584098        0.786545                 -0.092714       0  \n",
       "6           0.417134       -0.061786                 -0.754360       0  \n",
       "7          -1.676542        2.402972                 -0.944793       0  \n",
       "8           1.210530       -0.305860                  0.500771       1  \n",
       "9           1.316871        0.222439                 -0.003946       2  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#DISPLAY TOP 5 ROWS\n",
    "data = pd.read_csv(\"C:\\\\machine\\\\commerce-dataset.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.24568831 -0.84811566  0.59238466 ... -0.74003098  0.84156985\n",
      "  -1.97034714]\n",
      " [-1.17232281  0.03364377  0.43613436 ... -1.01396808  0.88089232\n",
      "  -0.78525331]\n",
      " [-0.04151851  0.28240994 -0.82889404 ...  0.56637192  0.84322125\n",
      "   0.15886304]\n",
      " ...\n",
      " [-0.29430557  0.54732491  1.45868918 ... -0.18934601 -0.09286142\n",
      "  -1.29003794]\n",
      " [-0.19140339  0.17657008  1.24056875 ...  0.47350013 -0.43188206\n",
      "  -1.85895264]\n",
      " [-0.35300072  1.51364061  0.28373126 ... -0.75587931  1.64742374\n",
      "  -1.16689615]]\n",
      "(200000, 22)\n",
      "(200000,)\n"
     ]
    }
   ],
   "source": [
    "X=data.drop(['CAREER'], axis = 1).values\n",
    "#data.drop(['name'])\n",
    "from sklearn import preprocessing \n",
    "Standardisation = preprocessing.StandardScaler() \n",
    "AFTER_SCALE= Standardisation.fit_transform(X) \n",
    "X=AFTER_SCALE\n",
    "print(X)\n",
    "y = data['CAREER']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NAIVE-BAYES-ACCURACY => 86.3725 %\n",
      "Time= 0.13268804550170898\n",
      "[[11226   427  1645]\n",
      " [   93 13000   345]\n",
      " [ 2320   621 10323]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.84      0.83     13298\n",
      "           1       0.93      0.97      0.95     13438\n",
      "           2       0.84      0.78      0.81     13264\n",
      "\n",
      "    accuracy                           0.86     40000\n",
      "   macro avg       0.86      0.86      0.86     40000\n",
      "weighted avg       0.86      0.86      0.86     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NAIVE  BAYES\n",
    "import time\n",
    "start=time.time()\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive=GaussianNB()\n",
    "naive.fit(X_train,y_train)\n",
    "y_pred = naive.predict(X_test)\n",
    "print(\"'NAIVE-BAYES-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"Time=\",end-start)\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC-REGRESSION-ACCURACY => 93.875 %\n",
      "time= 2.0929994583129883\n",
      "[[12620   380   298]\n",
      " [  141 12770   527]\n",
      " [  777   327 12160]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.95      0.94     13298\n",
      "           1       0.95      0.95      0.95     13438\n",
      "           2       0.94      0.92      0.93     13264\n",
      "\n",
      "    accuracy                           0.94     40000\n",
      "   macro avg       0.94      0.94      0.94     40000\n",
      "weighted avg       0.94      0.94      0.94     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "import time\n",
    "start=time.time()\n",
    "from sklearn import linear_model\n",
    "log=linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "log.fit(X_train,y_train)\n",
    "y_pred=(log.predict(X_test))\n",
    "print(\"LOGISTIC-REGRESSION-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\",end-start)\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP-ACCURACY => 97.5125 %\n",
      "time=56.67140483856201\n",
      "[[13135    80    83]\n",
      " [   54 13232   152]\n",
      " [  432   194 12638]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.98     13298\n",
      "           1       0.98      0.98      0.98     13438\n",
      "           2       0.98      0.95      0.97     13264\n",
      "\n",
      "    accuracy                           0.98     40000\n",
      "   macro avg       0.98      0.98      0.98     40000\n",
      "weighted avg       0.98      0.98      0.98     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#two hidden layers\n",
    "\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp= MLPClassifier(hidden_layer_sizes=(8,8), activation='relu', solver='adam',max_iter=200)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred=(mlp.predict(X_test))\n",
    "print(\"MLP-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\"+str(end-start))\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost-ACCURACY => 90.535 %\n",
      "time=36.084197998046875\n",
      "[[11773   320  1205]\n",
      " [  595 12477   366]\n",
      " [  867   433 11964]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89     13298\n",
      "           1       0.94      0.93      0.94     13438\n",
      "           2       0.88      0.90      0.89     13264\n",
      "\n",
      "    accuracy                           0.91     40000\n",
      "   macro avg       0.91      0.91      0.91     40000\n",
      "weighted avg       0.91      0.91      0.91     40000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Adaboost-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\"+str(end-start))\n",
    "\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************DECISION TREE***********************\n",
      "\n",
      "Predicted Value :\n",
      "[1 0 0 ... 2 1 0]\n",
      "\n",
      "Confusion Matrix : model evaluation\n",
      "[[12600   164   534]\n",
      " [  156 12968   314]\n",
      " [  502   337 12425]]\n",
      "\n",
      " Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95     13298\n",
      "           1       0.96      0.97      0.96     13438\n",
      "           2       0.94      0.94      0.94     13264\n",
      "\n",
      "    accuracy                           0.95     40000\n",
      "   macro avg       0.95      0.95      0.95     40000\n",
      "weighted avg       0.95      0.95      0.95     40000\n",
      "\n",
      "\n",
      "Decision Tree Accuracy : \n",
      "94.9825\n",
      "12.72\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#DECISION TREE\n",
    "print(\"******************DECISION TREE***********************\\n\")\n",
    "import time\n",
    "Start = time.time ()\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "Decision_tree= DecisionTreeClassifier(criterion = 'gini') \n",
    "Decision_tree.fit(X_train, y_train)\n",
    "Y_pred = Decision_tree.predict(X_test) \n",
    "print(\"Predicted Value :\")\n",
    "print(Y_pred)\n",
    "    \n",
    "print(\"\\nConfusion Matrix : model evaluation\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, Y_pred))\n",
    "    \n",
    "print(\"\\n Classification report :\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, Y_pred))\n",
    "    \n",
    "print(\"\\nDecision Tree Accuracy : \")\n",
    "from sklearn import metrics\n",
    "print((metrics.accuracy_score(y_test, Y_pred))*100)\n",
    "a2=(metrics.accuracy_score(y_test, Y_pred))*100\n",
    "end= time.time()\n",
    "b2=str(round(end-Start,2))\n",
    "print(b2)\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HUMAITIES DATASET - 1.5 LAKH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IQ</th>\n",
       "      <th>HISTORY</th>\n",
       "      <th>ECONOMICS</th>\n",
       "      <th>SOCIOLOGY</th>\n",
       "      <th>GEOGRAPHY</th>\n",
       "      <th>POLITICAL SCIENCE</th>\n",
       "      <th>LANGUAGE</th>\n",
       "      <th>OPENNESS</th>\n",
       "      <th>CONSCIENTIOUSNESS</th>\n",
       "      <th>EXTRAVERSION</th>\n",
       "      <th>...</th>\n",
       "      <th>SATISFACTION</th>\n",
       "      <th>SOCIO-ECONOMIC-FACTORS</th>\n",
       "      <th>M-SCORE</th>\n",
       "      <th>TEAM-WORK</th>\n",
       "      <th>COMPETIVE-EXAM-WINNER</th>\n",
       "      <th>LEADERSHIP-SKILL</th>\n",
       "      <th>WORK-LIFE-BALANCE</th>\n",
       "      <th>CERTIFICATIONS</th>\n",
       "      <th>SELF-LEARNING-CAPABILITY</th>\n",
       "      <th>CAREER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.651165</td>\n",
       "      <td>1.300911</td>\n",
       "      <td>-1.353804</td>\n",
       "      <td>-0.798610</td>\n",
       "      <td>0.329610</td>\n",
       "      <td>-0.261548</td>\n",
       "      <td>-0.957768</td>\n",
       "      <td>-1.955050</td>\n",
       "      <td>0.513994</td>\n",
       "      <td>-1.158827</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.811830</td>\n",
       "      <td>-0.157286</td>\n",
       "      <td>0.162584</td>\n",
       "      <td>0.204840</td>\n",
       "      <td>-1.601923</td>\n",
       "      <td>0.363536</td>\n",
       "      <td>-1.526603</td>\n",
       "      <td>-1.311694</td>\n",
       "      <td>1.435085</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.791091</td>\n",
       "      <td>2.197572</td>\n",
       "      <td>0.245021</td>\n",
       "      <td>-0.802328</td>\n",
       "      <td>0.235874</td>\n",
       "      <td>0.005891</td>\n",
       "      <td>-0.310359</td>\n",
       "      <td>0.267041</td>\n",
       "      <td>-0.002142</td>\n",
       "      <td>-1.418743</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418400</td>\n",
       "      <td>-0.273882</td>\n",
       "      <td>-0.235674</td>\n",
       "      <td>-0.677657</td>\n",
       "      <td>-0.685583</td>\n",
       "      <td>0.825671</td>\n",
       "      <td>-1.495240</td>\n",
       "      <td>-0.453347</td>\n",
       "      <td>1.257949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.377100</td>\n",
       "      <td>1.698003</td>\n",
       "      <td>0.855287</td>\n",
       "      <td>1.521133</td>\n",
       "      <td>-0.384961</td>\n",
       "      <td>0.271486</td>\n",
       "      <td>-0.387395</td>\n",
       "      <td>0.386461</td>\n",
       "      <td>-0.283040</td>\n",
       "      <td>1.512270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.247391</td>\n",
       "      <td>-0.191357</td>\n",
       "      <td>0.147334</td>\n",
       "      <td>-0.457842</td>\n",
       "      <td>0.778543</td>\n",
       "      <td>-0.829255</td>\n",
       "      <td>-0.222240</td>\n",
       "      <td>0.605101</td>\n",
       "      <td>1.111774</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.635528</td>\n",
       "      <td>1.250182</td>\n",
       "      <td>-0.270923</td>\n",
       "      <td>0.094553</td>\n",
       "      <td>0.436016</td>\n",
       "      <td>0.800798</td>\n",
       "      <td>-1.752165</td>\n",
       "      <td>-0.899055</td>\n",
       "      <td>1.683146</td>\n",
       "      <td>-1.498247</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.371508</td>\n",
       "      <td>0.343312</td>\n",
       "      <td>-1.115507</td>\n",
       "      <td>-1.675611</td>\n",
       "      <td>0.212248</td>\n",
       "      <td>0.345293</td>\n",
       "      <td>1.509444</td>\n",
       "      <td>-0.838128</td>\n",
       "      <td>-0.063052</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.545640</td>\n",
       "      <td>0.361642</td>\n",
       "      <td>0.538216</td>\n",
       "      <td>0.678140</td>\n",
       "      <td>-0.772476</td>\n",
       "      <td>-0.152779</td>\n",
       "      <td>1.464910</td>\n",
       "      <td>-0.388882</td>\n",
       "      <td>-0.505807</td>\n",
       "      <td>-0.160456</td>\n",
       "      <td>...</td>\n",
       "      <td>1.142675</td>\n",
       "      <td>-0.453620</td>\n",
       "      <td>0.182175</td>\n",
       "      <td>1.009956</td>\n",
       "      <td>2.127781</td>\n",
       "      <td>0.255813</td>\n",
       "      <td>0.893201</td>\n",
       "      <td>-1.166986</td>\n",
       "      <td>-1.092004</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.628001</td>\n",
       "      <td>-0.427956</td>\n",
       "      <td>0.220561</td>\n",
       "      <td>1.528417</td>\n",
       "      <td>-1.352700</td>\n",
       "      <td>0.945923</td>\n",
       "      <td>1.592168</td>\n",
       "      <td>0.791029</td>\n",
       "      <td>-0.562641</td>\n",
       "      <td>-1.879086</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030126</td>\n",
       "      <td>-0.443133</td>\n",
       "      <td>-1.010602</td>\n",
       "      <td>-0.683892</td>\n",
       "      <td>0.944334</td>\n",
       "      <td>0.517078</td>\n",
       "      <td>1.368210</td>\n",
       "      <td>-0.428064</td>\n",
       "      <td>-1.655066</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.593207</td>\n",
       "      <td>1.973183</td>\n",
       "      <td>-1.045402</td>\n",
       "      <td>0.909100</td>\n",
       "      <td>0.282931</td>\n",
       "      <td>-0.447765</td>\n",
       "      <td>2.042927</td>\n",
       "      <td>0.468185</td>\n",
       "      <td>1.038957</td>\n",
       "      <td>0.103532</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.367649</td>\n",
       "      <td>-0.719364</td>\n",
       "      <td>0.750667</td>\n",
       "      <td>-0.984020</td>\n",
       "      <td>0.706671</td>\n",
       "      <td>0.764143</td>\n",
       "      <td>-1.719395</td>\n",
       "      <td>-1.503220</td>\n",
       "      <td>1.297374</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.211892</td>\n",
       "      <td>-0.200643</td>\n",
       "      <td>0.392068</td>\n",
       "      <td>-0.923973</td>\n",
       "      <td>-0.911943</td>\n",
       "      <td>0.156456</td>\n",
       "      <td>-0.526392</td>\n",
       "      <td>1.615690</td>\n",
       "      <td>-0.296108</td>\n",
       "      <td>0.674054</td>\n",
       "      <td>...</td>\n",
       "      <td>0.560056</td>\n",
       "      <td>-1.708477</td>\n",
       "      <td>-3.576407</td>\n",
       "      <td>0.194535</td>\n",
       "      <td>-2.457085</td>\n",
       "      <td>-0.648021</td>\n",
       "      <td>-0.115144</td>\n",
       "      <td>-2.029960</td>\n",
       "      <td>-0.180381</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.087132</td>\n",
       "      <td>-1.758586</td>\n",
       "      <td>-0.437291</td>\n",
       "      <td>-0.937863</td>\n",
       "      <td>-1.048539</td>\n",
       "      <td>-2.785045</td>\n",
       "      <td>1.225086</td>\n",
       "      <td>0.295614</td>\n",
       "      <td>-0.674979</td>\n",
       "      <td>-1.638797</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.459069</td>\n",
       "      <td>2.336478</td>\n",
       "      <td>-1.444683</td>\n",
       "      <td>0.178842</td>\n",
       "      <td>-0.596059</td>\n",
       "      <td>-1.407105</td>\n",
       "      <td>0.277610</td>\n",
       "      <td>-0.818494</td>\n",
       "      <td>-0.009591</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.406793</td>\n",
       "      <td>0.652580</td>\n",
       "      <td>0.829022</td>\n",
       "      <td>-0.292334</td>\n",
       "      <td>1.435747</td>\n",
       "      <td>0.408889</td>\n",
       "      <td>0.551696</td>\n",
       "      <td>-0.367750</td>\n",
       "      <td>0.293027</td>\n",
       "      <td>0.125824</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561043</td>\n",
       "      <td>1.405128</td>\n",
       "      <td>-0.316851</td>\n",
       "      <td>0.300638</td>\n",
       "      <td>-0.490581</td>\n",
       "      <td>0.091890</td>\n",
       "      <td>0.329685</td>\n",
       "      <td>2.219113</td>\n",
       "      <td>-0.253444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         IQ   HISTORY  ECONOMICS  SOCIOLOGY  GEOGRAPHY  POLITICAL SCIENCE  \\\n",
       "0  1.651165  1.300911  -1.353804  -0.798610   0.329610          -0.261548   \n",
       "1  0.791091  2.197572   0.245021  -0.802328   0.235874           0.005891   \n",
       "2  1.377100  1.698003   0.855287   1.521133  -0.384961           0.271486   \n",
       "3 -1.635528  1.250182  -0.270923   0.094553   0.436016           0.800798   \n",
       "4 -0.545640  0.361642   0.538216   0.678140  -0.772476          -0.152779   \n",
       "5 -0.628001 -0.427956   0.220561   1.528417  -1.352700           0.945923   \n",
       "6 -0.593207  1.973183  -1.045402   0.909100   0.282931          -0.447765   \n",
       "7  0.211892 -0.200643   0.392068  -0.923973  -0.911943           0.156456   \n",
       "8  0.087132 -1.758586  -0.437291  -0.937863  -1.048539          -2.785045   \n",
       "9  0.406793  0.652580   0.829022  -0.292334   1.435747           0.408889   \n",
       "\n",
       "   LANGUAGE  OPENNESS  CONSCIENTIOUSNESS  EXTRAVERSION  ...  SATISFACTION  \\\n",
       "0 -0.957768 -1.955050           0.513994     -1.158827  ...     -0.811830   \n",
       "1 -0.310359  0.267041          -0.002142     -1.418743  ...     -0.418400   \n",
       "2 -0.387395  0.386461          -0.283040      1.512270  ...     -0.247391   \n",
       "3 -1.752165 -0.899055           1.683146     -1.498247  ...     -0.371508   \n",
       "4  1.464910 -0.388882          -0.505807     -0.160456  ...      1.142675   \n",
       "5  1.592168  0.791029          -0.562641     -1.879086  ...     -0.030126   \n",
       "6  2.042927  0.468185           1.038957      0.103532  ...     -1.367649   \n",
       "7 -0.526392  1.615690          -0.296108      0.674054  ...      0.560056   \n",
       "8  1.225086  0.295614          -0.674979     -1.638797  ...     -1.459069   \n",
       "9  0.551696 -0.367750           0.293027      0.125824  ...      0.561043   \n",
       "\n",
       "   SOCIO-ECONOMIC-FACTORS   M-SCORE  TEAM-WORK  COMPETIVE-EXAM-WINNER  \\\n",
       "0               -0.157286  0.162584   0.204840              -1.601923   \n",
       "1               -0.273882 -0.235674  -0.677657              -0.685583   \n",
       "2               -0.191357  0.147334  -0.457842               0.778543   \n",
       "3                0.343312 -1.115507  -1.675611               0.212248   \n",
       "4               -0.453620  0.182175   1.009956               2.127781   \n",
       "5               -0.443133 -1.010602  -0.683892               0.944334   \n",
       "6               -0.719364  0.750667  -0.984020               0.706671   \n",
       "7               -1.708477 -3.576407   0.194535              -2.457085   \n",
       "8                2.336478 -1.444683   0.178842              -0.596059   \n",
       "9                1.405128 -0.316851   0.300638              -0.490581   \n",
       "\n",
       "   LEADERSHIP-SKILL  WORK-LIFE-BALANCE  CERTIFICATIONS  \\\n",
       "0          0.363536          -1.526603       -1.311694   \n",
       "1          0.825671          -1.495240       -0.453347   \n",
       "2         -0.829255          -0.222240        0.605101   \n",
       "3          0.345293           1.509444       -0.838128   \n",
       "4          0.255813           0.893201       -1.166986   \n",
       "5          0.517078           1.368210       -0.428064   \n",
       "6          0.764143          -1.719395       -1.503220   \n",
       "7         -0.648021          -0.115144       -2.029960   \n",
       "8         -1.407105           0.277610       -0.818494   \n",
       "9          0.091890           0.329685        2.219113   \n",
       "\n",
       "   SELF-LEARNING-CAPABILITY  CAREER  \n",
       "0                  1.435085       1  \n",
       "1                  1.257949       1  \n",
       "2                  1.111774       2  \n",
       "3                 -0.063052       0  \n",
       "4                 -1.092004       2  \n",
       "5                 -1.655066       0  \n",
       "6                  1.297374       0  \n",
       "7                 -0.180381       1  \n",
       "8                 -0.009591       1  \n",
       "9                 -0.253444       2  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "#DISPLAY TOP 5 ROWS\n",
    "data = pd.read_csv(\"C:\\\\machine\\\\humanities-dataset.csv\")\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.65387287  1.29905166 -1.35037826 ... -1.53645037 -0.59739747\n",
      "   1.43158727]\n",
      " [ 0.79354715  2.19748708  0.24791042 ... -1.505026   -0.07371361\n",
      "   1.25453011]\n",
      " [ 1.37972835  1.69692931  0.85797214 ... -0.22954282  0.57205402\n",
      "   1.10842098]\n",
      " ...\n",
      " [ 1.23653922 -1.60844464 -1.50510814 ... -0.68939418  0.00466291\n",
      "  -1.06779219]\n",
      " [ 1.75261127  1.08815958 -0.06227623 ...  0.86284206 -0.17064843\n",
      "   1.33240845]\n",
      " [ 0.08564096 -0.92033662  0.91763489 ...  0.62457878 -0.495897\n",
      "   0.29817691]]\n",
      "(150000, 22)\n",
      "(150000,)\n"
     ]
    }
   ],
   "source": [
    "X=data.drop(['CAREER'], axis = 1).values\n",
    "#data.drop(['name'])\n",
    "from sklearn import preprocessing \n",
    "Standardisation = preprocessing.StandardScaler() \n",
    "AFTER_SCALE= Standardisation.fit_transform(X) \n",
    "X=AFTER_SCALE\n",
    "print(X)\n",
    "y = data['CAREER']\n",
    "print(X.shape)\n",
    "print(y.shape)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'NAIVE-BAYES-ACCURACY => 83.90333333333334 %\n",
      "Time= 0.1116337776184082\n",
      "[[7993  456 1511]\n",
      " [ 495 8114 1380]\n",
      " [ 140  847 9064]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      0.80      0.86      9960\n",
      "           1       0.86      0.81      0.84      9989\n",
      "           2       0.76      0.90      0.82     10051\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.85      0.84      0.84     30000\n",
      "weighted avg       0.85      0.84      0.84     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#NAIVE  BAYES\n",
    "import time\n",
    "start=time.time()\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "naive=GaussianNB()\n",
    "naive.fit(X_train,y_train)\n",
    "y_pred = naive.predict(X_test)\n",
    "print(\"'NAIVE-BAYES-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"Time=\",end-start)\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOGISTIC-REGRESSION-ACCURACY => 83.51666666666667 %\n",
      "time= 1.1849126815795898\n",
      "[[8660  396  904]\n",
      " [ 562 8091 1336]\n",
      " [ 607 1140 8304]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.87      0.88      9960\n",
      "           1       0.84      0.81      0.82      9989\n",
      "           2       0.79      0.83      0.81     10051\n",
      "\n",
      "    accuracy                           0.84     30000\n",
      "   macro avg       0.84      0.84      0.84     30000\n",
      "weighted avg       0.84      0.84      0.84     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "import time\n",
    "start=time.time()\n",
    "from sklearn import linear_model\n",
    "log=linear_model.LogisticRegression()\n",
    "\n",
    "\n",
    "log.fit(X_train,y_train)\n",
    "y_pred=(log.predict(X_test))\n",
    "print(\"LOGISTIC-REGRESSION-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\",end-start)\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP-ACCURACY => 91.14333333333333 %\n",
      "time=39.442617654800415\n",
      "[[8958  224  778]\n",
      " [ 190 9315  484]\n",
      " [ 364  617 9070]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.90      0.92      9960\n",
      "           1       0.92      0.93      0.92      9989\n",
      "           2       0.88      0.90      0.89     10051\n",
      "\n",
      "    accuracy                           0.91     30000\n",
      "   macro avg       0.91      0.91      0.91     30000\n",
      "weighted avg       0.91      0.91      0.91     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#two hidden layers\n",
    "\n",
    "import time\n",
    "start=time.time()\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "mlp= MLPClassifier(hidden_layer_sizes=(8,8), activation='relu', solver='adam',max_iter=200)\n",
    "mlp.fit(X_train,y_train)\n",
    "y_pred=(mlp.predict(X_test))\n",
    "print(\"MLP-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\"+str(end-start))\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adaboost-ACCURACY => 82.91 %\n",
      "time=26.657072067260742\n",
      "[[8771  224  965]\n",
      " [ 240 8678 1071]\n",
      " [1272 1355 7424]]\n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.88      0.87      9960\n",
      "           1       0.85      0.87      0.86      9989\n",
      "           2       0.78      0.74      0.76     10051\n",
      "\n",
      "    accuracy                           0.83     30000\n",
      "   macro avg       0.83      0.83      0.83     30000\n",
      "weighted avg       0.83      0.83      0.83     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start=time.time()\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "abc = AdaBoostClassifier()\n",
    "\n",
    "# Train Adaboost Classifer\n",
    "model = abc.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Adaboost-ACCURACY => \"+str(metrics.accuracy_score(y_test, y_pred)*100)+str(\" %\"))\n",
    "end=time.time()\n",
    "print(\"time=\"+str(end-start))\n",
    "\n",
    "\n",
    "#CLASSIFICATION REPORT\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "#CONFUSION MATRIX\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "******************DECISION TREE***********************\n",
      "\n",
      "Predicted Value :\n",
      "[1 1 1 ... 0 2 1]\n",
      "\n",
      "Confusion Matrix : model evaluation\n",
      "[[8739  384  837]\n",
      " [ 385 8809  795]\n",
      " [ 919  779 8353]]\n",
      "\n",
      " Classification report :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.88      0.87      9960\n",
      "           1       0.88      0.88      0.88      9989\n",
      "           2       0.84      0.83      0.83     10051\n",
      "\n",
      "    accuracy                           0.86     30000\n",
      "   macro avg       0.86      0.86      0.86     30000\n",
      "weighted avg       0.86      0.86      0.86     30000\n",
      "\n",
      "\n",
      "Decision Tree Accuracy : \n",
      "86.33666666666666\n",
      "8.08\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#DECISION TREE\n",
    "print(\"******************DECISION TREE***********************\\n\")\n",
    "import time\n",
    "Start = time.time ()\n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "Decision_tree= DecisionTreeClassifier(criterion = 'gini') \n",
    "Decision_tree.fit(X_train, y_train)\n",
    "Y_pred = Decision_tree.predict(X_test) \n",
    "print(\"Predicted Value :\")\n",
    "print(Y_pred)\n",
    "    \n",
    "print(\"\\nConfusion Matrix : model evaluation\")\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, Y_pred))\n",
    "    \n",
    "print(\"\\n Classification report :\")\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, Y_pred))\n",
    "    \n",
    "print(\"\\nDecision Tree Accuracy : \")\n",
    "from sklearn import metrics\n",
    "print((metrics.accuracy_score(y_test, Y_pred))*100)\n",
    "a2=(metrics.accuracy_score(y_test, Y_pred))*100\n",
    "end= time.time()\n",
    "b2=str(round(end-Start,2))\n",
    "print(b2)\n",
    "\n",
    "print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
